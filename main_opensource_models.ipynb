{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Attendance System\n",
    "\n",
    "This notebook implements a facial recognition-based attendance system using FaceNet and MTCNN. The system recognizes registered students, marks their attendance, and displays their information on a user interface.\n",
    "\n",
    "## Features\n",
    "- Real-time face detection and recognition\n",
    "- Student information display\n",
    "- Attendance tracking with cooldown periods\n",
    "- Firebase integration for storage and database\n",
    "- Custom UI with different status modes\n",
    "\n",
    "## Requirements\n",
    "- OpenCV\n",
    "- TensorFlow\n",
    "- Firebase Admin SDK\n",
    "- MTCNN\n",
    "- cvzone\n",
    "- FaceNet pre-trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cvzone\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import storage\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn import MTCNN\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Firebase\n",
    "\n",
    "Connect to Firebase for data storage and retrieval. You'll need your own service account credentials file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize Firebase with your credentials\n",
    "cred = credentials.Certificate(\"service.json\")  # Replace with your service account key\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': \"https://bigvision-22c68-default-rtdb.firebaseio.com/\",  # Update with your database URL\n",
    "    'storageBucket': \"bigvision-22c68.firebasestorage.app\"  # Update with your storage bucket\n",
    "})\n",
    "\n",
    "# Get storage bucket reference\n",
    "bucket = storage.bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Video Capture and UI Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize video capture (0 for default camera, or specify another index)\n",
    "cap = cv2.VideoCapture(0)  # Change to 1 if using external webcam\n",
    "cap.set(3, 640)  # Width\n",
    "cap.set(4, 480)  # Height\n",
    "\n",
    "# Load background image for UI\n",
    "imgBackground = cv2.imread('resources/background2.png')\n",
    "\n",
    "# Load mode images for different UI states\n",
    "folderModePath = 'resources/new_modes'\n",
    "modePathList = os.listdir(folderModePath)\n",
    "imgModeList = []\n",
    "for path in modePathList:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "print(f\"Loaded {len(imgModeList)} mode images for UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Face Detection and Recognition Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize MTCNN for face detection\n",
    "face_detector = MTCNN()\n",
    "print(\"MTCNN face detector initialized\")\n",
    "\n",
    "# Load FaceNet model for face embedding generation\n",
    "facenet_model_path = 'models/facenet_keras.h5'\n",
    "if not os.path.exists(facenet_model_path):\n",
    "    print(f\"ERROR: FaceNet model not found at {facenet_model_path}\")\n",
    "    print(\"Please download the model from: https://github.com/nyoki-mtl/keras-facenet\")\n",
    "    # You would exit here in a script, but in a notebook let's just raise an exception\n",
    "    raise FileNotFoundError(f\"FaceNet model not found at {facenet_model_path}\")\n",
    "\n",
    "facenet_model = load_model(facenet_model_path)\n",
    "print(\"FaceNet model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Existing Encodings (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the encoding file (or create empty lists if not exists)\n",
    "print(\"Loading Encode File...\")\n",
    "encode_file_path = 'FaceNetEncodeFile.p'\n",
    "if os.path.exists(encode_file_path):\n",
    "    with open(encode_file_path, 'rb') as file:\n",
    "        encodeListKnownWithIds = pickle.load(file)\n",
    "    encodeListKnown, studentIds = encodeListKnownWithIds\n",
    "    print(f\"Encode File Loaded with {len(encodeListKnown)} face encodings\")\n",
    "else:\n",
    "    print(\"No existing encode file found. Will create when enrolling new students.\")\n",
    "    encodeListKnown = []  # List to store face embeddings\n",
    "    studentIds = []       # List to store corresponding student IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define Constants and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Constants for timing (in frames, assuming ~25fps)\n",
    "ACTIVE_DISPLAY_TIME = 5 * 25      # 5 seconds for \"ACTIVE\" screen\n",
    "DETAILS_DISPLAY_TIME = 5 * 25     # 5 seconds for student details screen\n",
    "MARKED_DISPLAY_TIME = 2 * 25      # 2 seconds for \"MARKED\" screen (green checkmark)\n",
    "ALREADY_MARKED_DISPLAY_TIME = 3 * 25  # 3 seconds for \"ALREADY MARKED\" screen\n",
    "COOLDOWN_PERIOD = 60              # 1 minute cooldown before allowing re-marking\n",
    "SIMILARITY_THRESHOLD = 0.85       # Threshold for face match confidence (higher = stricter)\n",
    "\n",
    "# Mode Types:\n",
    "# 0: Scanning/Active mode\n",
    "# 1: Student details mode (photo, ID, name)\n",
    "# 2: Marked mode (green checkmark)\n",
    "# 3: Already marked mode\n",
    "\n",
    "# Initial states\n",
    "modeType = 0           # Start in scanning mode\n",
    "counter = 0            # Frame counter for timing\n",
    "id = -1                # Current student ID\n",
    "imgStudent = None      # Student image placeholder\n",
    "studentInfo = None     # Student info placeholder\n",
    "marked_students = {}   # Dictionary to track recently marked students {id: timestamp}\n",
    "face_detected = False  # Flag for face detection status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def preprocess_face(face_img, required_size=(160, 160)):\n",
    "    \"\"\"Preprocess face image for FaceNet input\n",
    "    \n",
    "    Args:\n",
    "        face_img: The face image to process\n",
    "        required_size: Target size for the image (FaceNet expects 160x160)\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed face image ready for embedding generation\n",
    "    \"\"\"\n",
    "    face_img = cv2.resize(face_img, required_size)\n",
    "    face_img = face_img.astype('float32')\n",
    "    # Standardize pixel values\n",
    "    mean, std = face_img.mean(), face_img.std()\n",
    "    face_img = (face_img - mean) / std\n",
    "    return face_img\n",
    "\n",
    "def get_embedding(face_img):\n",
    "    \"\"\"Generate embedding vector from preprocessed face using FaceNet\n",
    "    \n",
    "    Args:\n",
    "        face_img: Preprocessed face image\n",
    "        \n",
    "    Returns:\n",
    "        128-dimensional embedding vector\n",
    "    \"\"\"\n",
    "    # Expand dimensions to match the model's expected input\n",
    "    samples = np.expand_dims(face_img, axis=0)\n",
    "    # Get embeddings\n",
    "    yhat = facenet_model.predict(samples)\n",
    "    return yhat[0]\n",
    "\n",
    "def detect_faces(img):\n",
    "    \"\"\"Detect faces using MTCNN and return face locations and aligned faces\n",
    "    \n",
    "    Args:\n",
    "        img: Input frame from camera\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (face_locations, aligned_faces)\n",
    "    \"\"\"\n",
    "    # Convert to RGB for MTCNN\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Detect faces\n",
    "    results = face_detector.detect_faces(rgb_img)\n",
    "    \n",
    "    face_locations = []\n",
    "    aligned_faces = []\n",
    "    \n",
    "    for result in results:\n",
    "        # Get face box coordinates\n",
    "        x, y, w, h = result['box']\n",
    "        # Handle negative values sometimes returned by MTCNN\n",
    "        x, y = max(0, x), max(0, y)\n",
    "        face_img = rgb_img[y:y+h, x:x+w]\n",
    "        \n",
    "        # Skip if face is too small\n",
    "        if face_img.shape[0] < 20 or face_img.shape[1] < 20:\n",
    "            continue\n",
    "            \n",
    "        # Process and align face\n",
    "        try:\n",
    "            # Convert back to BGR for consistency with OpenCV\n",
    "            face_img = cv2.cvtColor(face_img, cv2.COLOR_RGB2BGR)\n",
    "            # Preprocess for FaceNet\n",
    "            processed_face = preprocess_face(face_img)\n",
    "            # Add to results\n",
    "            face_locations.append((y, x+w, y+h, x))  # Format: (top, right, bottom, left)\n",
    "            aligned_faces.append(processed_face)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing face: {e}\")\n",
    "            continue\n",
    "            \n",
    "    return face_locations, aligned_faces\n",
    "\n",
    "def compare_faces(known_embeddings, face_embedding, threshold=SIMILARITY_THRESHOLD):\n",
    "    \"\"\"Compare a face embedding with a list of known embeddings\n",
    "    \n",
    "    Args:\n",
    "        known_embeddings: List of known face embeddings\n",
    "        face_embedding: Current face embedding to compare\n",
    "        threshold: Similarity threshold (0-1)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (matches, similarities)\n",
    "    \"\"\"\n",
    "    if len(known_embeddings) == 0:\n",
    "        return [], []\n",
    "    \n",
    "    # Calculate similarity for each known face\n",
    "    similarities = []\n",
    "    for emb in known_embeddings:\n",
    "        similarity = cosine_similarity([emb], [face_embedding])[0][0]\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Create match results\n",
    "    matches = [sim >= threshold for sim in similarities]\n",
    "    \n",
    "    return matches, similarities\n",
    "\n",
    "def draw_centered_text(image, text, box_x, box_y, box_w, box_h, font_scale=0.6, thickness=2):\n",
    "    \"\"\"Draw text centered in a box area\n",
    "    \n",
    "    Args:\n",
    "        image: Image to draw on\n",
    "        text: Text to draw\n",
    "        box_x, box_y: Top-left coordinates of the box\n",
    "        box_w, box_h: Width and height of the box\n",
    "        font_scale: Text size\n",
    "        thickness: Text thickness\n",
    "    \"\"\"\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    text_width, text_height = text_size\n",
    "    x = box_x + (box_w - text_width) // 2\n",
    "    y = box_y + (box_h + text_height) // 2 - 5  # fine-tuned for vertical alignment\n",
    "    cv2.putText(image, text, (x, y), font, font_scale, (0, 0, 0), thickness)  # black color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Loop for Face Recognition and Attendance System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Starting face attendance system with FaceNet...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 1. Capture and prepare frame\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            print(\"Failed to get frame from camera\")\n",
    "            continue\n",
    "\n",
    "        # Create a copy of the background for each frame\n",
    "        imgBackground = cv2.imread('resources/background2.png')\n",
    "        \n",
    "        # Resize webcam feed to match the green box perfectly\n",
    "        imgResized = cv2.resize(img, (655, 380))\n",
    "\n",
    "        # Define top-left coordinate of the green box\n",
    "        x, y = 137, 244\n",
    "\n",
    "        # Paste webcam feed onto background\n",
    "        imgBackground[y:y+380, x:x+655] = imgResized\n",
    "        \n",
    "        # Create a copy to work with for drawing\n",
    "        imgBackgroundCopy = imgBackground.copy()\n",
    "\n",
    "        # Update the right panel image based on current mode\n",
    "        panelResized = cv2.resize(imgModeList[modeType], (438, 714))\n",
    "        panel_x, panel_y = 899, 23\n",
    "        imgBackgroundCopy[panel_y:panel_y+714, panel_x:panel_x+438] = panelResized\n",
    "\n",
    "        # 2. Process face detection in scanning mode\n",
    "        if modeType == 0:  # Scanning mode\n",
    "            # Detect and align faces\n",
    "            face_locations, processed_faces = detect_faces(img)\n",
    "            \n",
    "            # Reset face_detected flag\n",
    "            face_detected = False\n",
    "            \n",
    "            if face_locations and processed_faces:\n",
    "                for face_loc, processed_face in zip(face_locations, processed_faces):\n",
    "                    # Get the embedding for the current face\n",
    "                    face_embedding = get_embedding(processed_face)\n",
    "                    \n",
    "                    # Compare with known faces\n",
    "                    matches, similarities = compare_faces(encodeListKnown, face_embedding)\n",
    "                    \n",
    "                    if any(matches):\n",
    "                        # Find the best match\n",
    "                        match_index = np.argmax(similarities)\n",
    "                        \n",
    "                        # If match confidence is good enough\n",
    "                        if matches[match_index]:\n",
    "                            # Draw rectangle around face\n",
    "                            y1, x2, y2, x1 = face_loc\n",
    "                            bbox = x + x1, y + y1, x2 - x1, y2 - y1\n",
    "                            imgBackgroundCopy = cvzone.cornerRect(imgBackgroundCopy, bbox, rt=0)\n",
    "                            \n",
    "                            # Get student ID\n",
    "                            id = studentIds[match_index]\n",
    "                            face_detected = True\n",
    "                            \n",
    "                            # Check if student was recently marked (within cooldown period)\n",
    "                            current_time = datetime.now()\n",
    "                            if id in marked_students:\n",
    "                                time_diff = (current_time - marked_students[id]).total_seconds()\n",
    "                                \n",
    "                                # If within cooldown period, show \"Already Marked\" screen\n",
    "                                if time_diff < COOLDOWN_PERIOD:\n",
    "                                    counter = 1\n",
    "                                    modeType = 3  # Switch to \"Already Marked\" mode\n",
    "                                    \n",
    "                                    # Update right panel immediately for \"Already Marked\"\n",
    "                                    panelResized = cv2.resize(imgModeList[modeType], (438, 714))\n",
    "                                    imgBackgroundCopy[panel_y:panel_y+714, panel_x:panel_x+438] = panelResized\n",
    "                                    \n",
    "                                    print(f\"Student ID {id} already marked - showing 'Already Marked' screen\")\n",
    "                                    continue\n",
    "                            \n",
    "                            # 3. Fetch student data\n",
    "                            try:\n",
    "                                studentInfo = db.reference(f'Students/{id}').get()\n",
    "                                print(f\"Retrieved student info for ID {id}\")\n",
    "                                \n",
    "                                # Get student image from storage\n",
    "                                try:\n",
    "                                    blob = bucket.get_blob(f'images/{id}.jpeg')\n",
    "                                    if blob:\n",
    "                                        array = np.frombuffer(blob.download_as_string(), np.uint8)\n",
    "                                        imgStudent = cv2.imdecode(array, cv2.COLOR_BGRA2BGR)\n",
    "                                        print(f\"Successfully loaded student image for ID {id}\")\n",
    "                                    else:\n",
    "                                        print(f\"No image found for student ID {id}\")\n",
    "                                        imgStudent = None\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Error loading student image: {e}\")\n",
    "                                    imgStudent = None\n",
    "                                \n",
    "                                # 4. Update attendance in database\n",
    "                                if studentInfo and 'last_attendance_time' in studentInfo:\n",
    "                                    datetimeObject = datetime.strptime(studentInfo['last_attendance_time'], \n",
    "                                                                    \"%Y-%m-%d %H:%M:%S\")\n",
    "                                    secondsElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
    "                                    \n",
    "                                    # Update attendance if enough time has passed since last mark\n",
    "                                    if secondsElapsed > 30:  # Database cooldown check\n",
    "                                        ref = db.reference(f'Students/{id}')\n",
    "                                        studentInfo['total_attendance'] += 1\n",
    "                                        ref.child('total_attendance').set(studentInfo['total_attendance'])\n",
    "                                        ref.child('last_attendance_time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                                        \n",
    "                                        # Record this student as recently marked\n",
    "                                        marked_students[id] = datetime.now()\n",
    "                                        print(f\"Updated attendance for student ID {id}\")\n",
    "                                        \n",
    "                                        # Switch to \"Student Details\" mode (photo, ID, name)\n",
    "                                        counter = 1\n",
    "                                        modeType = 1\n",
    "                                        \n",
    "                                        # Update right panel immediately for \"Student Details\"\n",
    "                                        panelResized = cv2.resize(imgModeList[modeType], (438, 714))\n",
    "                                        imgBackgroundCopy[panel_y:panel_y+714, panel_x:panel_x+438] = panelResized\n",
    "                                    else:\n",
    "                                        # Student was marked too recently (database perspective)\n",
    "                                        counter = 1\n",
    "                                        modeType = 3  # Show as \"Already Marked\"\n",
    "                                        \n",
    "                                        # Update right panel immediately\n",
    "                                        panelResized = cv2.resize(imgModeList[modeType], (438, 714))\n",
    "                                        imgBackgroundCopy[panel_y:panel_y+714, panel_x:panel_x+438] = panelResized\n",
    "                                else:\n",
    "                                    print(f\"No attendance data for student ID {id}\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing student data: {e}\")\n",
    "                                counter = 0\n",
    "                                modeType = 0\n",
    "        \n",
    "        # 5. Handle mode transitions based on counters\n",
    "        if counter > 0:\n",
    "            counter += 1\n",
    "            \n",
    "            # After showing student details screen for specified time, transition to marked screen\n",
    "            if modeType == 1 and counter >= DETAILS_DISPLAY_TIME:\n",
    "                print(\"Transitioning from details to marked mode\")\n",
    "                modeType = 2  # Switch to marked mode (green checkmark)\n",
    "                counter = 1  # Reset counter for marked mode\n",
    "                \n",
    "                # Update the right panel immediately for marked\n",
    "                panelResized = cv2.resize(imgModeList[modeType], (438, 714))\n",
    "                imgBackgroundCopy[panel_y:panel_y+714, panel_x:panel_x+438] = panelResized\n",
    "            \n",
    "            # When in student details mode, display student information\n",
    "            if modeType == 1:\n",
    "                if studentInfo:\n",
    "                    # Display student information\n",
    "                    try:\n",
    "                        # Draw ID\n",
    "                        if id is not None:\n",
    "                            draw_centered_text(imgBackgroundCopy, str(id), 1025, 555, 100, -170)\n",
    "\n",
    "                        # Draw Name\n",
    "                        if 'name' in studentInfo:\n",
    "                            draw_centered_text(imgBackgroundCopy, studentInfo['name'], 1025, 555, 200, 40)\n",
    "\n",
    "                        # Display student image\n",
    "                        if imgStudent is not None and isinstance(imgStudent, np.ndarray) and imgStudent.size > 0:\n",
    "                            try:\n",
    "                                imgStudentResized = cv2.resize(imgStudent, (216, 216))\n",
    "                                imgBackgroundCopy[150:150 + 216, 1009:1009 + 216] = imgStudentResized\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error displaying student image: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error displaying student info: {e}\")\n",
    "            \n",
    "            # After showing \"Already Marked\" for specified time, return to scanning mode\n",
    "            elif modeType == 3 and counter >= ALREADY_MARKED_DISPLAY_TIME:\n",
    "                counter = 0\n",
    "                modeType = 0\n",
    "                studentInfo = None\n",
    "                imgStudent = None\n",
    "            \n",
    "            # After showing \"Marked\" screen (checkmark) for specified time, return to scanning mode\n",
    "            elif modeType == 2 and counter >= MARKED_DISPLAY_TIME:\n",
    "                counter = 0\n",
    "                modeType = 0\n",
    "                studentInfo = None\n",
    "                imgStudent = None\n",
    "        \n",
    "        # 6. Clean up expired entries in marked_students dictionary\n",
    "        current_time = datetime.now()\n",
    "        expired_ids = []\n",
    "        for student_id, mark_time in marked_students.items():\n",
    "            if (current_time - mark_time).total_seconds() > COOLDOWN_PERIOD:\n",
    "                expired_ids.append(student_id)\n",
    "        \n",
    "        for student_id in expired_ids:\n",
    "            del marked_students[student_id]\n",
    "        \n",
    "        # 7. Display the UI\n",
    "        cv2.imshow(\"Face Attendance System\", imgBackgroundCopy)\n",
    "        \n",
    "        # Check for key press (ESC to exit)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nAttendance system stopped by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError in attendance system: {e}\")\n",
    "finally:\n",
    "    # Clean up resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Resources released successfully\")"
   ]
  }
]
}